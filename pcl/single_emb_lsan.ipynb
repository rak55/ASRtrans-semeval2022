{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"single_emb_lsan.ipynb","provenance":[],"authorship_tag":"ABX9TyPjIpiZ3D3E8LWtnlpiyy70"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gi0OA6WRk7cd","executionInfo":{"status":"ok","timestamp":1638074978160,"user_tz":-330,"elapsed":21156,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"f14fc118-c8a8-425d-d48b-ab84395d184e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1en0ZTblLFO","executionInfo":{"status":"ok","timestamp":1638074979625,"user_tz":-330,"elapsed":2,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"1b214675-125b-43cb-aa82-886c66c00d44"},"source":["%cd /content/drive/My Drive/semeval_2022/dontpatronizeme_v1.3"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/semeval_2022/dontpatronizeme_v1.3\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXXNpgBHmQgr","executionInfo":{"status":"ok","timestamp":1638074990313,"user_tz":-330,"elapsed":4683,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"8781104c-82e8-48bf-c3ae-40d26d9b6815"},"source":["!pip install beautifulsoup4 "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"]}]},{"cell_type":"code","metadata":{"id":"uPG56ZDHmaUl"},"source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","import pickle\n","import h5py\n","import csv\n","import string "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0yWcMdEplLLN"},"source":["contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n","                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n","                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n","                       \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\",\n","                       \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n","                       \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n","                       \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n","                       \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n","                       \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n","                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n","                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n","                       \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n","                       \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\",\n","                       \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n","                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n","                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n","                       \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n","                       \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n","                       \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n","                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n","                       \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n","                       \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'u.s':'america', 'e.g':'for example'}\n","\n","punct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n"," '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n"," '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n"," '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n"," '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n","\n","punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\",\n","                 \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n","                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '!':' '}\n","\n","mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater',\n","                'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ',\n","                'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can',\n","                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', \n","                'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', \n","                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', \n","                'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization',\n","                'demonetisation': 'demonetization'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qE9cXTSTlLNV"},"source":["def clean_text(text):\n","    '''Clean emoji, Make text lowercase, remove text in square brackets,remove links,remove punctuation\n","    and remove words containing numbers.'''\n","    #text = emoji.demojize(text)\n","    text = re.sub(r'\\:(.*?)\\:','',text)\n","    text = str(text).lower()    #Making Text Lowercase\n","    text = re.sub('\\[.*?\\]', '', text)\n","    #The next 2 lines remove html text\n","    text = BeautifulSoup(text, 'lxml').get_text()\n","    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n","    text = re.sub('<.*?>+', '', text)\n","    text = re.sub('\\n', '', text)\n","    text = re.sub('\\w*\\d\\w*', '', text)\n","    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\")\n","    text = re.sub(r\"[^a-zA-Z?.!,¿']+\", \" \", text)\n","    return text\n","\n","def clean_contractions(text, mapping):\n","    '''Clean contraction using contraction mapping'''    \n","    specials = [\"’\", \"‘\", \"´\", \"`\"]\n","    for s in specials:\n","        text = text.replace(s, \"'\")\n","    for word in mapping.keys():\n","        if \"\"+word+\"\" in text:\n","            text = text.replace(\"\"+word+\"\", \"\"+mapping[word]+\"\")\n","    #Remove Punctuations\n","    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n","    # creating a space between a word and the punctuation following it\n","    # eg: \"he is a boy.\" => \"he is a boy .\"\n","    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n","    text = re.sub(r'[\" \"]+', \" \", text)\n","    return text\n","def clean_special_chars(text, punct, mapping):\n","    '''Cleans special characters present(if any)'''   \n","    for p in mapping:\n","        text = text.replace(p, mapping[p])\n","    \n","    for p in punct:\n","        text = text.replace(p, f' {p} ')\n","    \n","    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  \n","    for s in specials:\n","        text = text.replace(s, specials[s])\n","    \n","    return text\n","\n","def correct_spelling(x, dic):\n","    '''Corrects common spelling errors'''   \n","    for word in dic.keys():\n","        x = x.replace(word, dic[word])\n","    return x\n","\n","def remove_space(text):\n","    '''Removes awkward spaces'''   \n","    #Removes awkward spaces \n","    text = text.strip()\n","    text = text.split()\n","    return \" \".join(text)\n","\n","def text_preprocessing_pipeline(text):\n","    '''Cleaning and parsing the text.'''\n","    text = clean_text(text)\n","    text = clean_contractions(text, contraction_mapping)\n","    text = clean_special_chars(text, punct, punct_mapping)\n","    text = correct_spelling(text, mispell_dict)\n","    text = remove_space(text)\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eX4hbIMRlLQ_"},"source":["train_df=pd.read_csv('task2_train_pmaug.csv')\n","val_df=pd.read_csv('task2_test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k2MGvL30lLTr"},"source":["train_df['text'] = train_df['text'].apply(text_preprocessing_pipeline)\n","val_df['text'] = val_df['text'].apply(text_preprocessing_pipeline)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e-7L0JVRlLXW"},"source":["import torch\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","import torch.utils.data as data_utils"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rJdN7l0dnQes"},"source":["class BasicModule(torch.nn.Module):\n","    def __init__(self):\n","        super(BasicModule, self).__init__()\n","        self.model_name = str(type(self))\n","\n","    def load(self, path):\n","        self.load_state_dict(torch.load(path))\n","\n","    def save(self, path=None):\n","        if path is None:\n","            raise ValueError('Please specify the saving road!!!')\n","        torch.save(self.state_dict(), path)\n","        return path\n","\n","\n","class StructuredSelfAttention(BasicModule):\n","\n","    def __init__(self, batch_size, lstm_hid_dim, d_a, n_classes, label_embed, embeddings):\n","        super(StructuredSelfAttention, self).__init__()\n","        self.n_classes = n_classes\n","        self.embeddings = self._load_embeddings(embeddings)\n","        self.label_embed = self.load_labelembedd(label_embed)\n","        self.lstm = torch.nn.LSTM(300, hidden_size=lstm_hid_dim, num_layers=1,\n","                            batch_first=True, bidirectional=True)\n","        self.linear_first = torch.nn.Linear(lstm_hid_dim * 2, d_a) #W1 for attention\n","        self.linear_second = torch.nn.Linear(d_a, n_classes)       #W2 for attention\n","\n","        self.weight1 = torch.nn.Linear(lstm_hid_dim * 2, 1)     #for adaptive fusion\n","        self.weight2 = torch.nn.Linear(lstm_hid_dim * 2, 1)     #for adaptive fusion\n","\n","        self.output_layer = torch.nn.Linear(lstm_hid_dim*2, n_classes)\n","        self.embedding_dropout = torch.nn.Dropout(p=0.3)\n","        self.batch_size = batch_size\n","        self.lstm_hid_dim = lstm_hid_dim\n","\n","    def _load_embeddings(self, embeddings):\n","        \"\"\"Load the embeddings based on flag\"\"\"\n","        word_embeddings = torch.nn.Embedding(embeddings.size(0), embeddings.size(1))\n","        word_embeddings.weight = torch.nn.Parameter(embeddings)\n","        return word_embeddings\n","    def load_labelembedd(self, label_embed):\n","        \"\"\"Load the embeddings based on flag\"\"\"\n","        embed = torch.nn.Embedding(label_embed.size(0), label_embed.size(1))\n","        embed.weight = torch.nn.Parameter(label_embed)\n","        return embed\n","\n","    def init_hidden(self):\n","        return (torch.randn(2,self.batch_size,self.lstm_hid_dim).cuda(),torch.randn(2,self.batch_size,self.lstm_hid_dim).cuda())\n","\n","    def forward(self,x):\n","        embeddings = self.embeddings(x)\n","        embeddings = self.embedding_dropout(embeddings)\n","        #step1 get LSTM outputs\n","        hidden_state = self.init_hidden()\n","        outputs, hidden_state = self.lstm(embeddings, hidden_state)\n","        print(outputs.size())\n","        #step2 get self-attention\n","        selfatt = torch.tanh(self.linear_first(outputs))\n","        print(selfatt.size())\n","        selfatt = self.linear_second(selfatt)\n","        print(selfatt.size())\n","        selfatt = F.softmax(selfatt, dim=1)\n","        print(selfatt.size())\n","        selfatt= selfatt.transpose(1, 2)\n","        print(selfatt.size())\n","        self_att = torch.bmm(selfatt, outputs)\n","        print(self_att.size())   \n","        #step3 get label-attention\n","        h1 = outputs[:, :, :self.lstm_hid_dim]\n","        h2 = outputs[:, :,self.lstm_hid_dim:]\n","        \n","        label = self.label_embed.weight.data\n","        m1 = torch.bmm(label.expand(self.batch_size, self.n_classes, self.lstm_hid_dim), h1.transpose(1, 2))\n","        m2 = torch.bmm(label.expand(self.batch_size, self.n_classes, self.lstm_hid_dim), h2.transpose(1, 2))\n","        label_att= torch.cat((torch.bmm(m1,h1),torch.bmm(m2,h2)),2)\n","        # label_att = F.normalize(label_att, p=2, dim=-1)\n","        # self_att = F.normalize(self_att, p=2, dim=-1) #all can\n","        weight1=torch.sigmoid(self.weight1(label_att))\n","        weight2 = torch.sigmoid(self.weight2(self_att ))\n","        weight1 = weight1/(weight1+weight2)\n","        weight2= 1-weight1\n","\n","        doc = weight1*label_att+weight2*self_att\n","        # there two method, for simple, just add\n","        # also can use linear to do it\n","        avg_sentence_embeddings = torch.sum(doc, 1)/self.n_classes\n","\n","        pred = torch.sigmoid(self.output_layer(avg_sentence_embeddings))\n","        return pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m0Y4_kvbgGLO"},"source":["NUM_CALSSES=7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6yvUqO2anQhC"},"source":["def rec_label(tp, fn):\n","\tif (tp + fn) == 0:\n","\t\treturn -np.inf\n","\treturn tp/float(tp + fn)\n","\n","def prec_label(tp, fp):\n","\tif (tp + fp) == 0:\n","\t\treturn -np.inf\n","\treturn tp/float(tp + fp)\n","\n","def f_label(tp, fp, fn):\n","\tif (2*tp + fn + fp) == 0:\n","\t\treturn -np.inf\n","\treturn (2*tp)/float(2*tp + fn + fp)\n","\n","def components_F(pred, act):\n","\tTP = np.zeros(7)\n","\tFP = np.zeros(7)\n","\tFN = np.zeros(7)\n","\tfor l_id in range(7):\n","\t\tfor pr, ac in zip(pred, act):\n","\t\t\tif l_id in ac:\n","\t\t\t\tif l_id in pr:\n","\t\t\t\t\tTP[l_id] += 1\n","\t\t\t\telse:\n","\t\t\t\t\tFN[l_id] += 1\n","\t\t\telse:\n","\t\t\t\tif l_id in pr:\n","\t\t\t\t\tFP[l_id] += 1\n","\treturn TP, FP, FN\t\t\t\t\n","\n","def F_metrics_label_macro(pred, act):\n","\tTP, FP, FN = components_F(pred, act)\n","\treturn F_metrics_label_macro_from_comp(TP, FP, FN)\n","\n","def F_metrics_label_macro_from_comp(TP, FP, FN):\n","\tavgF = 0.0\n","\tavgP = 0.0\n","\tavgR = 0.0\n","\tfor tp, fp, fn in zip(TP,FP,FN):\n","\t\tavgP += prec_label(tp, fp)\n","\t\tavgR += rec_label(tp, fn)\n","\t\tavgF += f_label(tp, fp, fn)\n","\n","\treturn avgP/7, avgR/7, avgF/7\n","\n","def F_metrics_label_micro(pred, act):\n","\tTP, FP, FN = components_F(pred, act)\n","\treturn F_metrics_label_micro_from_comp(TP, FP, FN)\n","\n","def F_metrics_label_micro_from_comp(TP, FP, FN):\n","\tavgTP = np.mean(TP)\n","\tavgFP = np.mean(FP)\n","\tavgFN = np.mean(FN)\n","\treturn prec_label(avgTP, avgFP), rec_label(avgTP, avgFN), f_label(avgTP, avgFP, avgFN)\n"," \n","def f_indi(pred,act):\n","\tTP, FP, FN = components_F(pred, act)\n","\tpre_ind=[]\n","\trec_ind=[]\n","\tf1_ind=[]\n","\tfor i in range(7):\n","\t\tpre_ind.append(prec_label(TP[i],FP[i]))\n","\t\trec_ind.append(rec_label(TP[i],FN[i]))\n","\t\tf1_ind.append(f_label(TP[i],FP[i],FN[i]))\n","\treturn pre_ind,rec_ind,f1_ind\t\t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q31zP1jGO1bb"},"source":["from sklearn import metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VGmVR3mknQke"},"source":["def train(attention_model,train_loader,test_loader,criterion,opt,epochs = 5,GPU=True):\n","    if GPU:\n","        attention_model.cuda()\n","    for i in range(epochs):\n","        print(\"Running EPOCH\",i+1)\n","        train_loss = []\n","        #pre = []\n","        #recall = []\n","        #f1_micro=[]\n","        #f1_macro=[] \n","        best_val = 0\n","        for batch_idx, train in enumerate(tqdm(train_loader)):\n","            opt.zero_grad()\n","            x, y = train[0].cuda(), train[1].cuda()\n","            y_pred= attention_model(x)\n","            loss = criterion(y_pred, y.float())/train_loader.batch_size\n","            loss.backward()\n","            opt.step()\n","            labels_cpu = y.data.cpu().float()\n","            pred_cpu = y_pred.data.cpu()\n","            #TP,FP,FN=components_F(pred_cpu.numpy(),labels_cpu.numpy())\n","            #pl_ma, rl_ma, fl_ma = F_metrics_label_macro_from_comp(TP, FP, FN)\n","            #_,_,fl_mi=F_metrics_label_micro_from_comp(TP, FP, FN)\n","            #pre.append(pl_ma)\n","            #recall.append(rl_ma)\n","            #f1_micro.append(fl_mi)\n","            #f1_macro.append(fl_ma)\n","            train_loss.append(float(loss))\n","        avg_loss = np.mean(train_loss)\n","        #epoch_prec = np.array(pre).mean(axis=0)\n","        #epoch_rec = np.array(recall).mean(axis=0)\n","        #epoch_f1mi = np.array(f1_micro).mean(axis=0)\n","        #epoch_f1ma = np.array(f1_macro).mean(axis=0)\n","        print(\"epoch %2d train end : avg_loss = %.4f\" % (i+1, avg_loss))\n","        #print(\"precision : %.4f, recall : %.4f, f1_micro: %.4f, f1_macro: %.4f\" % (epoch_prec,epoch_rec,epoch_f1mi,epoch_f1ma))\n","        test_loss = []\n","        outputs=[]\n","        targets=[]\n","        #test_pre = []\n","        #test_rec=[]\n","        #test_f1mi=[]\n","        #test_f1ma=[]\n","        #test_f1ind=[]\n","        for batch_idx, test in enumerate(tqdm(test_loader)):\n","            x, y = test[0].cuda(), test[1].cuda()\n","            val_y= attention_model(x)\n","            loss = criterion(val_y, y.float()) /train_loader.batch_size\n","            labels_cpu = y.data.cpu().detach().float()\n","            pred_cpu = val_y.data.cpu().detach()\n","            outputs.extend(pred_cpu.numpy().tolist())\n","            targets.extend(labels_cpu.numpy().tolist())\n","            #TP,FP,FN=components_F(pred_cpu.numpy(),labels_cpu.numpy())\n","            #pl_ma, rl_ma, fl_ma = F_metrics_label_macro_from_comp(TP, FP, FN)\n","            #_,_,fl_mi=F_metrics_label_micro_from_comp(TP, FP, FN)\n","            #test_pre.append(pl_ma)\n","            #test_rec.append(rl_ma)\n","            #test_f1mi.append(fl_mi)\n","            #test_f1ma.append(fl_ma)\n","            #est_f1ind.append(f_indi(pred_cpu.numpy(),labels_cpu.numpy()))\n","            test_loss.append(float(loss))\n","        avg_test_loss = np.mean(test_loss)\n","        outputs=np.array(outputs)>=0.5\n","        f1mi=metrics.f1_score(targets, outputs, average='micro')\n","        f1ma=metrics.f1_score(targets, outputs, average='macro')\n","        #test_pre = np.array(test_pre).mean(axis=0)\n","        #test_rec = np.array(test_rec).mean(axis=0)\n","        #test_f1mi = np.array(test_f1mi).mean(axis=0)\n","        #test_f1ma = np.array(test_f1ma).mean(axis=0)\n","        #test_f1ind=np.array(test_f1ind).mean(axis=0)\n","        print(\"epoch %2d test end : avg_loss = %.4f, f1_micro = %.4f, f1_macro= %.4f\" % (i+1, avg_test_loss,f1mi,f1ma))\n","        #print(\"test_precision : %.4f, test_recall : %.4f, test_f1_micro: %.4f, test_f1_macro: %.4f\" % (test_pre,test_rec,test_f1mi,test_f1ma))\n","        #print('test_prec_ind')\n","        #print(test_f1ind[0])\n","        #print('test_rec_ind')\n","        #print(test_f1ind[1])\n","        #print('test_f1_ind')\n","        #print(test_f1ind[2])\n","        '''if f1ma > best_val:\n","          state={'epoch': i+1, 'state_dict':attention_model.state_dict(),'optimizer': opt.state_dict()}\n","          torch.save(state,'./saved_models/LSAN_glove_bce_eda.pt')'''\n","        \n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZ2BKPbDnQtB"},"source":["target_cols=['upr','ss','ps','av','m','c','pm']\n","X_train=train_df.text\n","X_test=val_df.text\n","y_train = torch.from_numpy(np.vstack(train_df[target_cols].values)).float()\n","y_test = torch.from_numpy(np.vstack(val_df[target_cols].values)).float()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gXzLSLfYT298"},"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7N8U5WCRT_jG"},"source":["def loadWRVModel(File):\n","    print(\"Loading Word Representation Vector Model\")\n","    f = open(File,'r')\n","    WRVModel = {}\n","    for line in f:\n","        splitLines = line.split()\n","        word = splitLines[0]\n","        try:\n","          wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n","        except:\n","          print(splitLines[1:])\n","          print(len(splitLines[1:]))\n","          break\n","        WRVModel[word] = wordEmbedding\n","    print(len(WRVModel),\" words loaded!\")\n","    return WRVModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rN_Ia5evUE4B","executionInfo":{"status":"ok","timestamp":1638075081675,"user_tz":-330,"elapsed":48181,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"786060b9-3792-49e8-dc5a-5abf892ef978"},"source":["WRVModel = loadWRVModel('./glove/glove.6B.300d.txt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Word Representation Vector Model\n","400001  words loaded!\n"]}]},{"cell_type":"code","metadata":{"id":"aQPaozjVU-ju"},"source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X_train)\n","\n","sequences_text_train = tokenizer.texts_to_sequences(X_train)\n","sequences_text_test = tokenizer.texts_to_sequences(X_test)\n","\n","X_train = torch.from_numpy(pad_sequences(sequences_text_train, maxlen=128, padding='post'))\n","X_test = torch.from_numpy(pad_sequences(sequences_text_test, maxlen=128, padding='post'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02sZHGx_Yoy2","executionInfo":{"status":"ok","timestamp":1638075082897,"user_tz":-330,"elapsed":3,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"ac415e25-7c25-4981-b683-c711726923d6"},"source":["print(X_train.shape)\n","print(X_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1066, 128])\n","torch.Size([199, 128])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aoxtbc6vVSu6","executionInfo":{"status":"ok","timestamp":1638075083506,"user_tz":-330,"elapsed":610,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"a5bc2160-0414-4a5d-c649-603c10eb64b7"},"source":["VOCAB_SIZE = len(tokenizer.word_index) + 1\n","embedding_matrix = torch.zeros(VOCAB_SIZE, 300)\n","\n","unk = 0\n","for i in range(1, VOCAB_SIZE):\n","  word = tokenizer.index_word[i]\n","  if word in WRVModel.keys():\n","    embedding_matrix[i] = torch.from_numpy(WRVModel[word]).float()\n","  else:\n","    unk +=1\n","print('VOCAB_SIZE : {}'.format(VOCAB_SIZE))\n","print('TOTAL OF UNKNOWN WORD : {}'.format(unk))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VOCAB_SIZE : 6957\n","TOTAL OF UNKNOWN WORD : 229\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1CYaYrHAY3ig","executionInfo":{"status":"ok","timestamp":1638075083506,"user_tz":-330,"elapsed":4,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"924b4da2-98b9-47fb-fa32-7789f5145497"},"source":["label_names=['unbalanced power relations','shallow solutions','presupposition','authority voice','metaphor','compassion','the poorer the merrier']\n","label_embedding = torch.zeros(7,300)\n","\n","for index, label in enumerate(label_names):\n","  words = label.split()\n","  num_of_words = len(words)\n","\n","  for sublabel in words:\n","    if sublabel in WRVModel.keys():\n","      label_embedding[index] +=  torch.from_numpy(WRVModel[sublabel])\n","  label_embedding[index] = label_embedding[index]/num_of_words\n","\n","print(label_embedding)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.0918, -0.1889, -0.0252,  ..., -0.3856,  0.1331,  0.0991],\n","        [ 0.0658,  0.3624, -0.2718,  ...,  0.0158, -0.0659, -0.0381],\n","        [ 0.5054, -0.7354,  0.2486,  ..., -0.0017,  0.4011, -0.5620],\n","        ...,\n","        [-0.3232, -0.6007,  0.4608,  ...,  0.2982,  0.0444,  0.4491],\n","        [-0.5578, -0.4172, -0.4372,  ...,  0.4248,  0.8330, -0.3659],\n","        [-0.1084, -0.0585,  0.1369,  ..., -0.0645, -0.0293, -0.0310]])\n"]}]},{"cell_type":"code","metadata":{"id":"lYKU6kIBaIVh"},"source":["epochs=50\n","lstm_hidden_dimension=300\n","batch_size=64\n","d_a=200\n","emb_size=300\n","GPU=True\n","use_cuda=True\n","label_num=7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xJiIxCvnQv6"},"source":["train_data = data_utils.TensorDataset(X_train,y_train)\n","test_data = data_utils.TensorDataset(X_test,y_test)\n","train_loader = data_utils.DataLoader(train_data, batch_size, shuffle=True, drop_last=True)\n","test_loader = data_utils.DataLoader(test_data, batch_size, drop_last=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Emgw8sG3arEO"},"source":["def multilabel_classification(attention_model, train_loader, test_loader, epochs, GPU=True):\n","    loss = torch.nn.BCELoss()\n","    opt = torch.optim.Adam(attention_model.parameters(), lr=0.001, betas=(0.9, 0.99))\n","    train(attention_model, train_loader, test_loader, loss, opt, epochs,GPU)\n","\n","attention_model = StructuredSelfAttention(batch_size=batch_size, lstm_hid_dim=lstm_hidden_dimension,\n","                                          d_a=d_a, n_classes=label_num, label_embed=label_embedding,embeddings=embedding_matrix)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b9Q7TfV2bPVN"},"source":["if use_cuda:\n","  attention_model.cuda()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kM-Pz4xZbPXS","executionInfo":{"status":"ok","timestamp":1638075105706,"user_tz":-330,"elapsed":7610,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"3979f3d7-c8a6-44a3-d6c4-ddcd4b7a502f"},"source":["multilabel_classification(attention_model, train_loader, test_loader, epochs=epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running EPOCH 1\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▋         | 1/16 [00:00<00:03,  3.78it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▎        | 2/16 [00:00<00:02,  5.54it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 4/16 [00:00<00:01,  7.41it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 7/16 [00:00<00:00,  9.10it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▋    | 9/16 [00:01<00:00,  9.92it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":[" 81%|████████▏ | 13/16 [00:01<00:00, 10.86it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:01<00:00,  9.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","epoch  1 train end : avg_loss = 0.0095\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/3 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 3/3 [00:00<00:00, 34.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","epoch  1 test end : avg_loss = 0.0081, f1_micro = 0.5090, f1_macro= 0.1656\n","Running EPOCH 2\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▎        | 2/16 [00:00<00:01, 12.36it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 4/16 [00:00<00:00, 12.13it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 6/16 [00:00<00:00, 11.93it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 8/16 [00:00<00:00, 11.84it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▎   | 10/16 [00:00<00:00, 11.81it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 12/16 [00:01<00:00, 11.74it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 14/16 [00:01<00:00, 11.83it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:01<00:00, 11.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch  2 train end : avg_loss = 0.0085\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/3 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 3/3 [00:00<00:00, 37.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","epoch  2 test end : avg_loss = 0.0077, f1_micro = 0.5219, f1_macro= 0.1776\n","Running EPOCH 3\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▎        | 2/16 [00:00<00:01, 11.57it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 4/16 [00:00<00:01, 11.76it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 6/16 [00:00<00:00, 11.79it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 8/16 [00:00<00:00, 11.80it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▎   | 10/16 [00:00<00:00, 11.86it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 12/16 [00:01<00:00, 11.88it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 14/16 [00:01<00:00, 11.86it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:01<00:00, 11.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch  3 train end : avg_loss = 0.0075\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/3 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 3/3 [00:00<00:00, 36.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","epoch  3 test end : avg_loss = 0.0075, f1_micro = 0.5302, f1_macro= 0.2428\n","Running EPOCH 4\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▎        | 2/16 [00:00<00:01, 11.32it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 4/16 [00:00<00:01, 11.66it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 6/16 [00:00<00:00, 11.71it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 8/16 [00:00<00:00, 11.80it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▎   | 10/16 [00:00<00:00, 11.72it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 12/16 [00:01<00:00, 11.77it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 14/16 [00:01<00:00, 11.68it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:01<00:00, 11.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch  4 train end : avg_loss = 0.0064\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/3 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 3/3 [00:00<00:00, 37.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","epoch  4 test end : avg_loss = 0.0073, f1_micro = 0.6147, f1_macro= 0.4200\n","Running EPOCH 5\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▎        | 2/16 [00:00<00:01, 12.07it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 4/16 [00:00<00:01, 11.96it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 6/16 [00:00<00:00, 11.93it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 8/16 [00:00<00:00, 11.85it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▎   | 10/16 [00:00<00:00, 11.86it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 12/16 [00:01<00:00, 11.91it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 14/16 [00:01<00:00, 11.92it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:01<00:00, 11.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch  5 train end : avg_loss = 0.0053\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/3 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 3/3 [00:00<00:00, 38.03it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 128, 600])\n","torch.Size([64, 128, 200])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 128, 7])\n","torch.Size([64, 7, 128])\n","torch.Size([64, 7, 128])\n","epoch  5 test end : avg_loss = 0.0077, f1_micro = 0.6395, f1_macro= 0.4453\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"id":"R_jt6ivCbPbA"},"source":[""],"execution_count":null,"outputs":[]}]}