{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mami_vit.ipynb","provenance":[],"authorship_tag":"ABX9TyM9EL5yyWJrMeY5sIymkwn8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"1DtGV4xh7SND","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642108631192,"user_tz":-330,"elapsed":20662,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"56743038-8cb5-4278-b5a7-491328de576e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/My Drive/semeval_2022/maMi"],"metadata":{"id":"BZ0g9z9E7gso","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642108631872,"user_tz":-330,"elapsed":682,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"65901ce5-c721-4aff-fc4a-ef3f9ef54ced"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/semeval_2022/maMi\n"]}]},{"cell_type":"code","source":["!pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrO9sy8rpryV","executionInfo":{"status":"ok","timestamp":1642108635115,"user_tz":-330,"elapsed":3245,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"520bcd5e-6916-4429-a7da-8baf75f470ac"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 38.2 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 42.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 38.9 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 41.7 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 37.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 18.1 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.15.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import glob, warnings\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","\n","warnings.filterwarnings('ignore')\n","print('TensorFlow Version ' + tf.__version__)"],"metadata":{"id":"XEDCSKN17guQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642108637394,"user_tz":-330,"elapsed":2281,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"a6e006e0-c6b5-4275-f30d-b7c336211767"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow Version 2.7.0\n"]}]},{"cell_type":"code","source":["IMAGE_SIZE = 224\n","BATCH_SIZE = 16\n","EPOCHS = 7\n","img_folder='./TRAINING/'\n","train_df=pd.read_csv('train.csv',sep='\\t')\n","val_df=pd.read_csv('test.csv',sep='\\t')"],"metadata":{"id":"zwFbHyP77gyJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMAGE_SIZE = 224\n","BATCH_SIZE = 16\n","img_folder='./test/'\n","test_df=pd.read_csv('./test/Test.csv',sep='\\t')"],"metadata":{"id":"I3vVLqD5Q2W_","executionInfo":{"status":"ok","timestamp":1642108644084,"user_tz":-330,"elapsed":383,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def data_augment(image):\n","    p_spatial = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n","    p_rotate = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n","    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n","    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n","    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n","    \n","    # Flips\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_flip_up_down(image)\n","    \n","    if p_spatial > .75:\n","        image = tf.image.transpose(image)\n","        \n","    # Rotates\n","    if p_rotate > .75:\n","        image = tf.image.rot90(image, k = 3) # rotate 270º\n","    elif p_rotate > .5:\n","        image = tf.image.rot90(image, k = 2) # rotate 180º\n","    elif p_rotate > .25:\n","        image = tf.image.rot90(image, k = 1) # rotate 90º\n","        \n","    # Pixel-level transforms\n","    if p_pixel_1 >= .4:\n","        image = tf.image.random_saturation(image, lower = .7, upper = 1.3)\n","    if p_pixel_2 >= .4:\n","        image = tf.image.random_contrast(image, lower = .8, upper = 1.2)\n","    if p_pixel_3 >= .4:\n","        image = tf.image.random_brightness(image, max_delta = .1)\n","        \n","    return image"],"metadata":{"id":"xxIh3AdA7g0f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#seeee class mode"],"metadata":{"id":"v7WgiogjRKv7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n","                                                          samplewise_center = True,\n","                                                          samplewise_std_normalization = True,\n","                                                          validation_split = 0.2,\n","                                                          preprocessing_function = data_augment)\n","\n","train_gen = datagen.flow_from_dataframe(dataframe = train_df,\n","                                        directory = img_folder,\n","                                        x_col = 'file_name',\n","                                        y_col = 'misogynous',\n","                                        subset = 'training',\n","                                        batch_size = BATCH_SIZE,\n","                                        seed = 1,\n","                                        color_mode = 'rgb',\n","                                        shuffle = True,\n","                                        class_mode = 'raw',\n","                                        target_size = (IMAGE_SIZE, IMAGE_SIZE))\n","\n","valid_gen = datagen.flow_from_dataframe(dataframe = train_df,\n","                                        directory = img_folder,\n","                                        x_col = 'file_name',\n","                                        y_col = 'misogynous',\n","                                        subset = 'validation',\n","                                        batch_size = BATCH_SIZE,\n","                                        seed = 1,\n","                                        color_mode = 'rgb',\n","                                        shuffle = False,\n","                                        class_mode = 'raw',\n","                                        target_size = (IMAGE_SIZE, IMAGE_SIZE))\n","\n","test_gen = datagen.flow_from_dataframe(dataframe = val_df,\n","                                        directory = img_folder,\n","                                        x_col = 'file_name',\n","                                        y_col = 'misogynous',\n","                                        batch_size = BATCH_SIZE,\n","                                        seed = 1,\n","                                        color_mode = 'rgb',\n","                                        shuffle = False,\n","                                        class_mode = 'raw',\n","                                        target_size = (IMAGE_SIZE, IMAGE_SIZE))\n"],"metadata":{"id":"1HP04i6q7g4S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640348055665,"user_tz":-330,"elapsed":53484,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"3950aff6-dbf4-45d1-f77d-1c06975262ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 6384 validated image filenames.\n","Found 1596 validated image filenames.\n","Found 2020 validated image filenames.\n"]}]},{"cell_type":"code","source":["datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n","                                                          samplewise_center = True,\n","                                                          samplewise_std_normalization = True)"],"metadata":{"id":"UAr1VIMTRe8X","executionInfo":{"status":"ok","timestamp":1642108645086,"user_tz":-330,"elapsed":1,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["test_gen = datagen.flow_from_dataframe(dataframe = test_df,\n","                                        directory = img_folder,\n","                                        x_col = 'file_name',\n","                                        y_col = None,\n","                                        batch_size = BATCH_SIZE,\n","                                        seed = 1,\n","                                        color_mode = 'rgb',\n","                                        shuffle = False,\n","                                        class_mode = None,\n","                                        target_size = (IMAGE_SIZE, IMAGE_SIZE))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iFZVicgfQyfj","executionInfo":{"status":"ok","timestamp":1642108647834,"user_tz":-330,"elapsed":379,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"44c99716-2f19-40e9-f0d4-6c8a3e7e1e9e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 validated image filenames.\n"]}]},{"cell_type":"code","source":["!pip install --quiet vit-keras\n","\n","from vit_keras import vit"],"metadata":{"id":"HAYJlF9e7g6t","executionInfo":{"status":"ok","timestamp":1642108658739,"user_tz":-330,"elapsed":3561,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#### seee classes 1 or 2"],"metadata":{"id":"m5V4sSfsQ7if"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vit_model = vit.vit_b32(\n","        image_size = IMAGE_SIZE,\n","        activation = 'sigmoid',\n","        pretrained = True,\n","        include_top = False,\n","        pretrained_top = False,\n","        classes=1)"],"metadata":{"id":"x98Jmb7M7g_I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640285933061,"user_tz":-330,"elapsed":17877,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"9100c840-8219-4908-a53c-fee5c8231ca2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-B_32_imagenet21k+imagenet2012.npz\n","353255424/353253686 [==============================] - 7s 0us/step\n","353263616/353253686 [==============================] - 7s 0us/step\n"]}]},{"cell_type":"code","source":[""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F16yBu6dqNwL","executionInfo":{"status":"ok","timestamp":1640285935647,"user_tz":-330,"elapsed":388,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"94ce6eb4-fc13-4758-fcf5-0ded47bedd6f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.engine.functional.Functional at 0x7f24c2aed5d0>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["from vit_keras import visualize\n","\n","x = test_gen.next()\n","image = x[0]\n","\n","attention_map = visualize.attention_map(model = vit_model, image = image)\n","\n","# Plot results\n","fig, (ax1, ax2) = plt.subplots(ncols = 2)\n","ax1.axis('off')\n","ax2.axis('off')\n","ax1.set_title('Original')\n","ax2.set_title('Attention Map')\n","_ = ax1.imshow(image)\n","_ = ax2.imshow(attention_map)"],"metadata":{"id":"8w_CVjKiG394","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1640285959687,"user_tz":-330,"elapsed":5171,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"a62e807b-fc9f-4a1e-ea79-9011c00a92e2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-441c680cb943>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mattention_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvit_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Plot results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/vit_keras/visualize.py\u001b[0m in \u001b[0;36mattention_map\u001b[0;34m(model, image)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Prepare the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Get the attention weights from each transformer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3363: error: (-215:Assertion failed) !dsize.empty() in function 'resize'\n"]}]},{"cell_type":"code","source":["model = tf.keras.Sequential([\n","        vit_model,\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dense(11, activation = tfa.activations.gelu),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dense(1, 'sigmoid')\n","    ],\n","    name = 'vision_transformer')\n","\n","model.summary()"],"metadata":{"id":"su9N-irNG4AA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640285987220,"user_tz":-330,"elapsed":2052,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"2acf5066-5d76-4a17-ebb1-7159b0d48a9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vision_transformer\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vit-b32 (Functional)        (None, 768)               87455232  \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," batch_normalization (BatchN  (None, 768)              3072      \n"," ormalization)                                                   \n","                                                                 \n"," dense (Dense)               (None, 11)                8459      \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 11)               44        \n"," hNormalization)                                                 \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 12        \n","                                                                 \n","=================================================================\n","Total params: 87,466,819\n","Trainable params: 87,465,261\n","Non-trainable params: 1,558\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["learning_rate = 1e-4\n","\n","optimizer = tfa.optimizers.RectifiedAdam(learning_rate = learning_rate)\n","\n","model.compile(optimizer = optimizer, \n","              loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.2), \n","              metrics = ['accuracy'])\n","\n","STEP_SIZE_TRAIN = train_gen.n // train_gen.batch_size\n","STEP_SIZE_VALID = valid_gen.n // valid_gen.batch_size\n","\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',\n","                                                 factor = 0.2,\n","                                                 patience = 2,\n","                                                 verbose = 1,\n","                                                 min_delta = 1e-4,\n","                                                 min_lr = 1e-6,\n","                                                 mode = 'max')\n","\n","earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n","                                                 min_delta = 1e-4,\n","                                                 patience = 5,\n","                                                 mode = 'max',\n","                                                 restore_best_weights = True,\n","                                                 verbose = 1)\n","checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath = './saved_models/vit_binary_image_checkpoint.hdf5',\n","                                                  monitor = 'val_accuracy', \n","                                                  verbose = 1, \n","                                                  save_best_only = True,\n","                                                  save_weights_only = True,\n","                                                  mode = 'max')\n","\n","callbacks = [earlystopping, reduce_lr, checkpointer]\n","\n","model.fit(x = train_gen,\n","          steps_per_epoch = STEP_SIZE_TRAIN,\n","          validation_data = valid_gen,\n","          validation_steps = STEP_SIZE_VALID,\n","          epochs = EPOCHS,\n","          callbacks = callbacks)\n","model.save('./saved_models/vit_binary_image_model.h5')"],"metadata":{"id":"rPUXHcING4Du","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640317796444,"user_tz":-330,"elapsed":31787173,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"8464604d-ef55-4542-aa9e-b493b5380ff1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/7\n","399/399 [==============================] - ETA: 0s - loss: 0.7696 - accuracy: 0.5667 \n","Epoch 00001: val_accuracy improved from -inf to 0.65152, saving model to ./saved_models/vit_binary_image_checkpoint.hdf5\n","399/399 [==============================] - 4619s 11s/step - loss: 0.7696 - accuracy: 0.5667 - val_loss: 0.6604 - val_accuracy: 0.6515 - lr: 1.0000e-04\n","Epoch 2/7\n","399/399 [==============================] - ETA: 0s - loss: 0.6622 - accuracy: 0.6385 \n","Epoch 00002: val_accuracy improved from 0.65152 to 0.67866, saving model to ./saved_models/vit_binary_image_checkpoint.hdf5\n","399/399 [==============================] - 4493s 11s/step - loss: 0.6622 - accuracy: 0.6385 - val_loss: 0.6410 - val_accuracy: 0.6787 - lr: 1.0000e-04\n","Epoch 3/7\n","399/399 [==============================] - ETA: 0s - loss: 0.6434 - accuracy: 0.6676 \n","Epoch 00003: val_accuracy did not improve from 0.67866\n","399/399 [==============================] - 4440s 11s/step - loss: 0.6434 - accuracy: 0.6676 - val_loss: 0.6415 - val_accuracy: 0.6761 - lr: 1.0000e-04\n","Epoch 4/7\n","399/399 [==============================] - ETA: 0s - loss: 0.6314 - accuracy: 0.6789 \n","Epoch 00004: val_accuracy improved from 0.67866 to 0.70202, saving model to ./saved_models/vit_binary_image_checkpoint.hdf5\n","399/399 [==============================] - 4535s 11s/step - loss: 0.6314 - accuracy: 0.6789 - val_loss: 0.6271 - val_accuracy: 0.7020 - lr: 1.0000e-04\n","Epoch 5/7\n","399/399 [==============================] - ETA: 0s - loss: 0.6309 - accuracy: 0.6859 \n","Epoch 00005: val_accuracy did not improve from 0.70202\n","399/399 [==============================] - 4486s 11s/step - loss: 0.6309 - accuracy: 0.6859 - val_loss: 0.6315 - val_accuracy: 0.6843 - lr: 1.0000e-04\n","Epoch 6/7\n","399/399 [==============================] - ETA: 0s - loss: 0.6172 - accuracy: 0.6961 \n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n","\n","Epoch 00006: val_accuracy did not improve from 0.70202\n","399/399 [==============================] - 4568s 11s/step - loss: 0.6172 - accuracy: 0.6961 - val_loss: 0.6630 - val_accuracy: 0.6503 - lr: 1.0000e-04\n","Epoch 7/7\n","399/399 [==============================] - ETA: 0s - loss: 0.5869 - accuracy: 0.7426 \n","Epoch 00007: val_accuracy did not improve from 0.70202\n","399/399 [==============================] - 4518s 11s/step - loss: 0.5869 - accuracy: 0.7426 - val_loss: 0.6312 - val_accuracy: 0.6938 - lr: 2.0000e-05\n"]}]},{"cell_type":"code","source":["from keras.models import load_model"],"metadata":{"id":"6QAy-Wv-RHdG","executionInfo":{"status":"ok","timestamp":1642108667939,"user_tz":-330,"elapsed":402,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model=load_model('./saved_models/vit_binary_image_model.h5')"],"metadata":{"id":"glvPuHqkQCfI","executionInfo":{"status":"ok","timestamp":1642108687177,"user_tz":-330,"elapsed":17965,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["predicted_classes = np.round(model.predict(test_gen, steps = test_gen.n // test_gen.batch_size + 1))\n","true_classes = test_gen.classes\n","class_labels = list(test_gen.class_indices.keys())  \n","\n","confusionmatrix = confusion_matrix(true_classes, predicted_classes)\n","plt.figure(figsize = (16, 16))\n","sns.heatmap(confusionmatrix, cmap = 'Blues', annot = True, cbar = True)\n","\n","print(classification_report(true_classes, predicted_classes))"],"metadata":{"id":"7O7zbb1vG4Gm","colab":{"base_uri":"https://localhost:8080/","height":234},"executionInfo":{"status":"error","timestamp":1640348590855,"user_tz":-330,"elapsed":510609,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"b93dfcb6-58c3-4842-f21b-77b55c1c8423"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-eb07f6de72ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredicted_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrue_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclass_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfusionmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrameIterator' object has no attribute 'classes'"]}]},{"cell_type":"code","source":["outputs = np.round(model.predict(test_gen, steps = test_gen.n // test_gen.batch_size + 1))\n","outputs=list(map(int,outputs))\n","predictions_db = pd.DataFrame(data=test_df['file_name'])\n","predictions_db['misogynist'] = outputs\n","predictions_db.to_csv('./final_res/answer9.txt', index=False, sep='\\t', header=False)"],"metadata":{"id":"GJTC_ajNR_77","executionInfo":{"status":"ok","timestamp":1642108912627,"user_tz":-330,"elapsed":220666,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["predicted_classes"],"metadata":{"id":"sDmbQ4ZX7hCA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640349419845,"user_tz":-330,"elapsed":405,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"c1537a34-3326-4d20-abd4-dd87eca2ce48"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.],\n","       [0.],\n","       [1.],\n","       ...,\n","       [0.],\n","       [0.],\n","       [1.]], dtype=float32)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["print(classification_report(val_df.misogynous.values, predicted_classes))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jhU0QXBccUx","executionInfo":{"status":"ok","timestamp":1640349493467,"user_tz":-330,"elapsed":6,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"a6dd8d08-6ddb-438c-938f-edd9423556a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.71      0.84      0.77       999\n","           1       0.81      0.67      0.73      1021\n","\n","    accuracy                           0.75      2020\n","   macro avg       0.76      0.75      0.75      2020\n","weighted avg       0.76      0.75      0.75      2020\n","\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score"],"metadata":{"id":"yiUFoG3ecuOh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mi=f1_score(val_df.misogynous.values,predicted_classes,average='macro')"],"metadata":{"id":"a1RF7nr8c81n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H04BmJDydMcw","executionInfo":{"status":"ok","timestamp":1640349631579,"user_tz":-330,"elapsed":380,"user":{"displayName":"ailneni rao 19210068","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giseq-GUEEEHxpbIRj6F3acRsPjOAw-9WWZZRWdDw=s64","userId":"10632211144139647575"}},"outputId":"a6eb113a-b06d-4fa9-c5dc-9d0f1c5ede4a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7484806143177922"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":[""],"metadata":{"id":"yTJnKHfxdNS_"},"execution_count":null,"outputs":[]}]}